{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     14
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opencv_python==4.5.2\n",
      "numpy==1.19.2\n",
      "matplotlib==3.3.2\n",
      "PIL==8.0.1\n",
      "G:\\Facultate\\Master anul I\\Semestrul II\\Computer Vision\\CV-2021-Project2\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import PIL\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import uniform\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "print(\"opencv_python==\" + cv.__version__)\n",
    "print(\"numpy==\" + np.__version__)\n",
    "print(\"matplotlib==\" + matplotlib.__version__)\n",
    "print(\"PIL==\" + PIL.__version__)\n",
    "\n",
    "dirname = os.path.abspath('')\n",
    "\n",
    "print(dirname)\n",
    "\n",
    "def list_of_files(dir_name, extension=\"png\"):\n",
    "    \"\"\"\n",
    "    Helper function that returns a list of all \n",
    "    files in a directory with a specific extension\n",
    "    :param dir_name.\n",
    "    :param extension.\n",
    "    :return List of all files with that specific extension\n",
    "    \"\"\"\n",
    "    return [f for f in glob.glob(dir_name+\"*.\" + extension)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgs_path = list_of_files(dirname + \"/Train/Task1/\", \"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     41
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show_image(image, window_name='image'):\n",
    "    \"\"\"\n",
    "    Helper function used to show images\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.title(window_name)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "\n",
    "def check_if_inside_circle(point, circle_origin, circle_radius):\n",
    "    \"\"\"\n",
    "    Helper function that check if the euclidean distance between a point and the \n",
    "    circle center is smaller that the radius. If yes, then the point isinside the circle\n",
    "    \"\"\"\n",
    "    print(((point[0] - circle_origin[0])**2 + (point[1] - circle_origin[1])**2))\n",
    "    if ((point[0] - circle_origin[0])**2 + (point[1] - circle_origin[1])**2) <= circle_radius:\n",
    "        return 1\n",
    "    return 0\n",
    "    \n",
    "def color_classificator(image):\n",
    "    \"\"\"\n",
    "    Helper function that classifies the color of a image based on a threshold technique\n",
    "    done using the HSV color space.\n",
    "    \"\"\"\n",
    "    \n",
    "    # according to https://stackoverflow.com/questions/32522989/opencv-better-detection-of-red-color\n",
    "    # a good method to mask the red color in an image is to invert the colors of the image\n",
    "    # and then detect cyan using a simple threshold\n",
    "    rgb_inv = cv.bitwise_not(image)\n",
    "\n",
    "    hsv = cv.cvtColor(image, cv.COLOR_RGB2HSV)\n",
    "    hsv_inv = cv.cvtColor(rgb_inv, cv.COLOR_RGB2HSV)\n",
    "    \n",
    "    red_mask = cv.inRange(hsv_inv, (90 - 10, 72, 50), (90 + 10, 255, 255))\n",
    "    yellow_mask = cv.inRange(hsv, (20, 100, 100), (30, 255, 255))\n",
    "    \n",
    "    # if there are more red pixels in the image return 0, the label for red \n",
    "    # if not, return 1, the label for yellow color\n",
    "    if np.sum(red_mask) > np.sum(yellow_mask):\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "def show_keypoints(image_, keypoints_):\n",
    "    \"\"\"\n",
    "    Show the keypoints found in the image.\n",
    "    \"\"\"\n",
    "    image_output = image_.copy()\n",
    "    image_output = cv.drawKeypoints(image_, keypoints_, image_output, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    show_image(image_output, 'keypoints')\n",
    "\n",
    "def find_big_red_circle(bgr):\n",
    "    \"\"\"\n",
    "    Find information about the characteristics of the curling court and \n",
    "    extract the color masked image for the two important colors: red and yellow\n",
    "    1. Mask the initial image to extract red and yellow regions.\n",
    "    2. Extract information about the house (big cyan circle)\n",
    "    3. Extract the diameter of the red circle \n",
    "    \n",
    "    :param bgr: The Blue-Green-Red image\n",
    "    :return diameter_of_a_stone - the diameter of the red circle that will be used to determine the radius of the stone\n",
    "    :return cyan_circle_coords - the center and the radius of the house\n",
    "    :return dilated_img - filtered image of the color masks\n",
    "    \"\"\"\n",
    "    \n",
    "    # sharpen the image\n",
    "    blur=cv.GaussianBlur(bgr,(0,0),3)\n",
    "    bgr=cv.addWeighted(bgr,1.5,blur,-0.5,0)\n",
    "\n",
    "    # invert the image\n",
    "    bgr_inv = cv.bitwise_not(bgr)\n",
    "\n",
    "    # convert from BGR to HSV for a better thresholding\n",
    "    hsv = cv.cvtColor(bgr, cv.COLOR_BGR2HSV)\n",
    "    hsv_inv = cv.cvtColor(bgr_inv, cv.COLOR_BGR2HSV)\n",
    "\n",
    "    # extract red, yellow and cyan masks\n",
    "    red_mask = cv.inRange(hsv_inv, (90 - 10, 72, 50), (90 + 10, 255, 255))\n",
    "    yellow_mask = cv.inRange(hsv, (20, 100, 100), (30, 255, 255))\n",
    "    cyan_mask = cv.inRange(hsv, (90 - 10, 72, 50), (90 + 10, 255, 255))\n",
    "    \n",
    "    # extract the biggest contour from the cyan mask\n",
    "    cyan_contours, _ = cv.findContours(cyan_mask,cv.RETR_TREE,cv.CHAIN_APPROX_SIMPLE)\n",
    "    cyan_cnt = sorted(cyan_contours, key=cv.contourArea, reverse=True)\n",
    "    biggest_cyan_cont = cyan_cnt[0:2]\n",
    "    \n",
    "    height, width, _ = bgr.shape\n",
    "    min_x, min_y = width, height\n",
    "    max_x = max_y = 0\n",
    "    \n",
    "    cont = np.zeros_like(cyan_mask)\n",
    "\n",
    "    # get the bounding rect of the biggest cyan contour\n",
    "    (x,y,w,h) = cv.boundingRect(biggest_cyan_cont[0])\n",
    "    min_x, max_x = min(x, min_x), max(x+w, max_x)\n",
    "    min_y, max_y = min(y, min_y), max(y+h, max_y)\n",
    "\n",
    "    # calculate the radius of the cyan circle\n",
    "    cyan_circle_radius = int(max(max_x-min_x, max_y-min_y)/2)\n",
    "    \n",
    "    # cyan circle origin and radius\n",
    "    cyan_circle_coords = [x+cyan_circle_radius, y+cyan_circle_radius, cyan_circle_radius]\n",
    "            \n",
    "    bgr = cv.circle(bgr,(x+cyan_circle_radius,y+cyan_circle_radius), 20, 255, -1)\n",
    "    \n",
    "\n",
    "    # extract the biggest contours from the red mask\n",
    "    red_contours, _ = cv.findContours(red_mask,cv.RETR_TREE,cv.CHAIN_APPROX_SIMPLE)\n",
    "    red_cnt = sorted(red_contours, key=cv.contourArea, reverse=True)\n",
    "    biggest_red_cont = red_cnt[0:2]\n",
    "    \n",
    "    height, width, _ = bgr.shape\n",
    "    min_x, min_y = width, height\n",
    "    max_x = max_y = 0\n",
    "    \n",
    "    cont = np.zeros_like(red_mask)\n",
    "\n",
    "    # get the bounding rect of the biggest red contour\n",
    "    (x,y,w,h) = cv.boundingRect(biggest_red_cont[0])\n",
    "    min_x, max_x = min(x, min_x), max(x+w, max_x)\n",
    "    min_y, max_y = min(y, min_y), max(y+h, max_y)\n",
    "\n",
    "    # according to http://howardcenter.org/wp-content/uploads/2019/03/Curling-101.pdf\n",
    "    # the diameter of the red circle has 4 feet and the diameter of the curling stone \n",
    "    # has around 11 inches. So, the diameter of the red circle is ~4.35 bigger than the\n",
    "    # diameter of the stone\n",
    "    diameter_of_a_stone = int(max(max_x-min_x, max_y-min_y)/4.35)\n",
    "    \n",
    "    # draw the red contours (the interior of the house and the red stones)\n",
    "    for i in range(2,20):\n",
    "        cv.drawContours(cont,[red_cnt[i]],0,255,-1)\n",
    "    \n",
    "#     show_image(bgr)\n",
    "        \n",
    "    cont += yellow_mask\n",
    "    \n",
    "    # use dillation to dillate the activated pixels\n",
    "    cont = cv.medianBlur(cont, 11)\n",
    "    dilated_img = cv.dilate(cont,(11,11),iterations = 1)\n",
    "\n",
    "    return diameter_of_a_stone, cyan_circle_coords, dilated_img\n",
    "        \n",
    "def count_stones(bgr, task_no=1):\n",
    "    \"\"\"\n",
    "    Extract information about the stones according to the requirements of each task\n",
    "    1. Declare a SimpleBlobDetector with its parameters\n",
    "    2. Extract the stones from the detected blobs\n",
    "    3. For task one, count the total number of the stones and the number for each color\n",
    "    4. For task two, determine the distance between the stone center and the house center, \n",
    "                    if the stones are in the house and their color\n",
    "    \n",
    "    :param bgr: The Blue-Green-Red image\n",
    "    :param task_no: The task number\n",
    "    :return total_stones  - for task 1, the total number of stones\n",
    "    :return red_stones    - for task 1, the total number of red stones\n",
    "    :return yellow_stones - for task 1, the total number of yellow stones\n",
    "    :return stone_data    - for task 2, the data about the stones\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize the simple blob detector params\n",
    "    params = cv.SimpleBlobDetector_Params()\n",
    "\n",
    "    # use only the params needed for our task, which are the area and inertia (how elongated a shape is)\n",
    "    params.filterByArea = True\n",
    "    params.filterByCircularity = False\n",
    "    params.filterByColor = False\n",
    "    params.filterByConvexity = False\n",
    "    params.filterByInertia = True\n",
    "\n",
    "    # Change thresholds\n",
    "    params.minThreshold = 0;\n",
    "    params.maxThreshold = 255;\n",
    "\n",
    "    rgb = cv.cvtColor(bgr, cv.COLOR_BGR2RGB)\n",
    "    \n",
    "    # get the information about the house and the color masked image\n",
    "    diameter_of_a_stone, cyan_circle_coords, cont = find_big_red_circle(bgr)\n",
    "\n",
    "    gray = cv.cvtColor(bgr, cv.COLOR_BGR2GRAY)    \n",
    "\n",
    "    gray = cv.GaussianBlur(gray, ksize=(5,5),sigmaX=0)\n",
    "\n",
    "    # set the area params for the blobs to be related to the \n",
    "    params.maxArea = (math.pi * (diameter_of_a_stone/2 * 1.2) ** 2) \n",
    "    params.minArea = (math.pi * (diameter_of_a_stone/2 * 0.4) ** 2) \n",
    "\n",
    "    # for a circle, this value is 1, for an ellipse it is between 0 and 1, and for a line it is 0.\n",
    "    params.maxInertiaRatio = 1\n",
    "    params.minInertiaRatio = 0.45\n",
    "\n",
    "    # create the detector and detect the blobs\n",
    "    detector = cv.SimpleBlobDetector_create(params)\n",
    "    keypoints = detector.detect(cont)\n",
    "    \n",
    "    total_stones = len(keypoints)\n",
    "    \n",
    "    red_stones = 0\n",
    "    yellow_stones = 0\n",
    "\n",
    "    stone_distances = []\n",
    "    stone_colors = []\n",
    "    stone_in_house = []\n",
    "    \n",
    "    for keypoint in keypoints:\n",
    "        # get the stones coordinates\n",
    "        stone = (rgb[int(max(keypoint.pt[1] - keypoint.size/2,0)) : int(max(keypoint.pt[1] + keypoint.size/2,0)),\n",
    "                 int(max(keypoint.pt[0] - keypoint.size/2,0)) : int(max(keypoint.pt[0] + keypoint.size/2,0))])\n",
    "        # classify the color of the stone\n",
    "        color = color_classificator(stone)\n",
    "        stone_colors.append(color)\n",
    "        # stone center\n",
    "        stone_center = (int(keypoint.pt[0]), int(keypoint.pt[1]))\n",
    "        # stone radius\n",
    "        stone_radius = int(keypoint.size/2)\n",
    "        \n",
    "        # count the red and yellow stones\n",
    "        if task_no == 1:\n",
    "            if color == 0:\n",
    "                cv.circle(rgb, stone_center, stone_radius, (255, 0, 0), 3)\n",
    "                red_stones += 1\n",
    "            else:\n",
    "                cv.circle(rgb, stone_center, stone_radius, (255, 255, 0), 3)\n",
    "                yellow_stones += 1\n",
    "        \n",
    "        # calculate the distance to house center and if the stones are in the house\n",
    "        if task_no == 2:\n",
    "            cv.circle(rgb, stone_center, stone_radius, (255, 0, 0), 3)\n",
    "            cv.circle(rgb, (cyan_circle_coords[0], cyan_circle_coords[1]), cyan_circle_coords[2], (0, 255, 255), 3)\n",
    "            \n",
    "            house_center = np.array((cyan_circle_coords[0], cyan_circle_coords[1]))\n",
    "\n",
    "            stone_distances.append(np.linalg.norm(house_center-np.array(stone_center)))\n",
    "            \n",
    "            stone_in_house.append(np.linalg.norm(house_center-np.array(stone_center)) <= cyan_circle_coords[2] + stone_radius * 1.5)\n",
    "    \n",
    "#     show_image(rgb)\n",
    "    \n",
    "    if task_no == 1:\n",
    "        show_image(rgb, str(total_stones) + str(red_stones) + str(yellow_stones))\n",
    "        plt.show()\n",
    "        return total_stones, red_stones, yellow_stones\n",
    "    if task_no == 2:\n",
    "        stone_data = np.array([stone_distances, stone_in_house, stone_colors])\n",
    "        # sort the data in ascending order on the distance characteristic\n",
    "        stone_data = stone_data[:, stone_data[0, :].argsort()]\n",
    "        return stone_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluate_task1(train_or_test='Train'):\n",
    "    \"\"\"\n",
    "    Evaluate task 1 on the 'Task1' input set\n",
    "    :param train_or_test. The source of the files. It can be either 'train' or 'test'.\n",
    "            To find the input images, the root folder where the notebook is located is taken\n",
    "            into consideration.\n",
    "    :output. The files with the resulting output will be saved at:\n",
    "            <current_directory>/evaluation/submission_files/Task1/\"\n",
    "    \"\"\"\n",
    "    print(\"Evaluate task 1\")\n",
    "    # get the path to the images and define all the other necessary paths\n",
    "    imgs_path = list_of_files(dirname + \"\\\\\"  + train_or_test + \"\\\\Task1\\\\\")\n",
    "    predictions_path_root = \"\\\\evaluation\\\\submission_files\\\\\"\n",
    "    predictions_path = dirname + predictions_path_root + \"Task1\\\\\"\n",
    "\n",
    "    # get each image\n",
    "    for i in range(len(imgs_path)):\n",
    "        if i == 1:\n",
    "            \n",
    "            print(\"Image \" + str(i+1) + \" from \" + str(len(imgs_path)) + \" for task 1\")\n",
    "            bgr = cv.imread(imgs_path[i])\n",
    "            rgb = cv.cvtColor(bgr, cv.COLOR_BGR2RGB)\n",
    "\n",
    "            show_image(rgb)\n",
    "\n",
    "            # get the stone numbers\n",
    "            total_stones, red_stones, yellow_stones = count_stones(bgr, task_no=1)\n",
    "            img_no = imgs_path[i].split(\"\\\\\")[-1].split(\".\")[0]\n",
    "\n",
    "            # save the results, line by line, to *_predicted files\n",
    "            with open(predictions_path + str(img_no) + '_predicted.txt','w') as f:\n",
    "                f.write(str(total_stones) + \"\\n\")\n",
    "                f.write(str(red_stones) + \"\\n\")\n",
    "                f.write(str(yellow_stones))\n",
    "        \n",
    "        \n",
    "            break\n",
    "            \n",
    "# evaluate_task1(train_or_test='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluate_task2(train_or_test='Train'):\n",
    "    \"\"\"\n",
    "    Evaluate task 2 on the 'Task2' input set\n",
    "    :param train_or_test. The source of the files. It can be either 'train' or 'test'.\n",
    "            To find the input images, the root folder where the notebook is located is taken\n",
    "            into consideration.\n",
    "    :output. The files with the resulting output will be saved at:\n",
    "            <current_directory>/evaluation/submission_files/Task2/\"\n",
    "    \"\"\"\n",
    "    print(\"Evaluate task 2\")\n",
    "    # get the path to the images and define all the other necessary paths\n",
    "    imgs_path = list_of_files(dirname + \"\\\\\"  + train_or_test + \"\\\\Task2\\\\\", \"mp4\")\n",
    "    predictions_path_root = \"\\\\evaluation\\\\submission_files\\\\\"\n",
    "    predictions_path = dirname + predictions_path_root + \"Task2\\\\\"\n",
    "    \n",
    "    # get each video\n",
    "    for i in range(len(imgs_path)): \n",
    "        cap = cv.VideoCapture(imgs_path[i])\n",
    "        \n",
    "        # get the number of frames\n",
    "        no_of_frames = cap.get(cv.CAP_PROP_FRAME_COUNT)\n",
    "        \n",
    "        # get the frames dimensions\n",
    "        width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        \n",
    "        img = np.zeros((height, width, 3))\n",
    "        \n",
    "        # this variable is used to define how many of the last frames to average\n",
    "        # to extract only the \"background\" of the curling house.\n",
    "        # with this procedure we will remain only with the house and stones, the \n",
    "        # motion of the players being weighted and thus, removed\n",
    "        frames_to_get = 25\n",
    "        \n",
    "        # get the last frames_to_get frames and average them\n",
    "        for j in range(frames_to_get):\n",
    "            cap.set(1, no_of_frames-j)\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                img += frame/(frames_to_get)\n",
    "        \n",
    "        # get the information about each stone in the last frames_to_get frames\n",
    "        stone_data = count_stones(img.astype(np.uint8), task_no = 2)\n",
    "            \n",
    "        print(\"Image \" + str(i+1) + \" from \" + str(len(imgs_path)) + \" for task 2\")\n",
    "        img_no = imgs_path[i].split(\"\\\\\")[-1].split(\".\")[0]\n",
    "\n",
    "        scoring_team = stone_data[2][0]\n",
    "        score = 0\n",
    "        \n",
    "        # determine the score by iterating through the stones\n",
    "        for k in range(len(stone_data[2, :])):\n",
    "            # check if we have the stone in the house\n",
    "            if stone_data[1,k]:\n",
    "                # if yes, then check if the stone is from the scoring team\n",
    "                if stone_data[2,k] == scoring_team:\n",
    "                    score += 1\n",
    "                else:\n",
    "                    # different team\n",
    "                    break\n",
    "            else:\n",
    "                # out of the house\n",
    "                break\n",
    "                \n",
    "        print(img_no)\n",
    "\n",
    "        # save the results, line by line, to *_predicted files\n",
    "        with open(predictions_path + str(img_no) + '_predicted.txt','w') as f:\n",
    "            if scoring_team == 0:\n",
    "                f.write(str(score) + \"\\n\")\n",
    "                f.write(str(0))\n",
    "            else:\n",
    "                f.write(str(0) + \"\\n\")\n",
    "                f.write(str(score))\n",
    "                \n",
    "        cap.release()\n",
    "            \n",
    "# evaluate_task2(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0,
     9,
     35,
     45,
     62,
     71
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_uniform_particles(x_range, y_range, N):\n",
    "    \"\"\"\n",
    "    A particle is a bounding box, represented by the top left corner and fixed width and height\n",
    "    \"\"\"\n",
    "    particles = np.empty((N, 2))\n",
    "    particles[:, 0] = uniform(x_range[0], x_range[1], size=N)\n",
    "    particles[:, 1] = uniform(y_range[0], y_range[1], size=N) \n",
    "    return particles\n",
    "\n",
    "def predict(particles, velocity, std, frame, w, h):\n",
    "    \"\"\"\n",
    "    Predict where the particles will be at the next frame by applying some dynamics\n",
    "    take into account velocity and some random noise.\n",
    "    \"\"\"\n",
    "    \n",
    "    N = len(particles)    \n",
    "    \n",
    "    noise = np.random.randn(N) * std[0]  \n",
    "    for i in range(N):\n",
    "        particles[i, 0] = particles[i, 0] + velocity[0] + noise[i]\n",
    "        # check that the particle is not outside of the image\n",
    "        if(particles[i, 0] > frame.shape[1] - w):\n",
    "            particles[i, 0] = frame.shape[1] - w\n",
    "        if(particles[i, 0] < 0):\n",
    "            particles[i, 0] = 0\n",
    "            \n",
    "    noise = np.random.randn(N) * std[1]\n",
    "    for i in range(N):\n",
    "        particles[i, 1] = particles[i, 1] + velocity[1] + noise[i]\n",
    "        if(particles[i, 1] > frame.shape[0] - h):\n",
    "            particles[i, 1] = frame.shape[0] - h\n",
    "        if(particles[i, 1] < 0):\n",
    "            particles[i, 1] = 0 \n",
    "    return particles\n",
    "\n",
    "def estimate(particles, weights):   \n",
    "    \"\"\"\n",
    "    Estimate the center of the cloud of particles.\n",
    "    \"\"\"\n",
    "    mean = np.float64(np.array([0, 0]))\n",
    "    N = particles.shape[0]  \n",
    "    for i in range(N): \n",
    "        mean += weights[i] * particles[i, :]   \n",
    "    return mean\n",
    "\n",
    "def resample(weights):\n",
    "    \"\"\"\n",
    "    Resample particles based on their weight.\n",
    "    \"\"\"\n",
    "    w = weights.flatten()\n",
    "    N = len(w)    \n",
    "    tries = np.random.multinomial(N, w)  \n",
    "    indexes = np.zeros(N, 'i')\n",
    "    cumsum_vector = np.cumsum(tries)\n",
    "    pos = -1 \n",
    "    for i in range(len(tries)):\n",
    "        for j in range(tries[i]):            \n",
    "            pos = pos + 1\n",
    "            indexes[pos] = i\n",
    "            \n",
    "    return indexes\n",
    "\n",
    "def resample_from_index(particles, weights, indexes):\n",
    "    \"\"\"\n",
    "    Using the new indexes, keep only the particles and the weights corresponsing to the indexes. Then, re-normalize the weights.\n",
    "    \"\"\"\n",
    "    particles[:] = particles[indexes]\n",
    "    weights[:] = weights[indexes]\n",
    "    weights /= np.sum(weights)\n",
    "    return particles, weights\n",
    "\n",
    "def select_roi(frame, bbox):\n",
    "    \"\"\"\n",
    "    Select the roi from the image.\n",
    "    :param frame\n",
    "    :return roi, x, y, w, h\n",
    "    \"\"\"\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "\n",
    "    roi = frame[y_min: y_max, x_min: x_max]\n",
    "         \n",
    "    return roi, x_min, y_min, x_max-x_min, y_max-y_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0,
     67,
     92,
     101,
     204
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def detect_frame(net, frame, show_detection=False):\n",
    "    \"\"\"\n",
    "    Use the YOLOv3 network to detect the stones and their color.\n",
    "    The YOLOv3 architecture was used by performing Transfer Learning using this tutorial:\n",
    "    https://medium.com/analytics-vidhya/yolov3-custom-object-detection-with-transfer-learning-47186c8f166d\n",
    "    The dataset was manually labeled having 140 images containing from 1 to 8 stones.\n",
    "    The training process took about 12 hours on Google Colab, having an average IOU of 0.83.\n",
    "    \n",
    "    :param net: the YOLOv3 network\n",
    "    :param frame: the frame where the detection will take place\n",
    "    :show_detection: use to draw the results\n",
    "    :return boxes: the bounding boxes of the detections\n",
    "    :return confidences: the confidences of the detections\n",
    "    :return class_ids: the color classes of the detections (0 for red, 1 for yellow)\n",
    "    \"\"\"\n",
    "    \n",
    "    height, width, _ = frame.shape\n",
    "    \n",
    "    # create a blob from image\n",
    "    blob = cv.dnn.blobFromImage(frame, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)\n",
    "\n",
    "    # forward the image through the network\n",
    "    net.setInput(blob)\n",
    "    output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "    layerOutputs = net.forward(output_layers_names)\n",
    "\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "\n",
    "    # write the bounding boxes coordinated, the confidence and the class id for each of the boxes\n",
    "    for output in layerOutputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.2:\n",
    "                center_x = int(detection[0]*width)\n",
    "                center_y = int(detection[1]*height)\n",
    "                w = int(detection[2]*width)\n",
    "                h = int(detection[3]*height)\n",
    "\n",
    "                x1 = int(center_x - w/2)\n",
    "                y1 = int(center_y - h/2)\n",
    "                \n",
    "                x2 = int(center_x + w/2)\n",
    "                y2 = int(center_y + h/2)\n",
    "\n",
    "                boxes.append([x1, y1, x2, y2])\n",
    "                confidences.append((float(confidence)))\n",
    "                class_ids.append(class_id)\n",
    "    \n",
    "    if show_detection:\n",
    "        indexes = cv.dnn.NMSBoxes(boxes, confidences, 0.2, 0.4)\n",
    "        if len(indexes)>0:\n",
    "            for i in indexes.flatten():\n",
    "                x, y, w, h = boxes[i]\n",
    "                label = str(class_ids[i])\n",
    "                confidence = str(round(confidences[i],2))\n",
    "                color = (255,0,0)\n",
    "                cv.rectangle(frame, (x,y), (x+w, y+h), color, 2)\n",
    "                cv.putText(frame, label + \" \" + confidence, (x, y+20), cv.FONT_HERSHEY_PLAIN, 1, (255,255,255), 2)\n",
    "        cv.imshow('annotated_image', frame)   \n",
    "        cv.waitKey(0)\n",
    "        \n",
    "    return boxes, confidences, class_ids\n",
    "\n",
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    \"\"\"\n",
    "    Get the IOU metric.\n",
    "    :params: boxA - first box\n",
    "    :params: boxB - second box\n",
    "    :return: iou  - the IOU value\n",
    "    \"\"\"\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the intersection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    # return the intersection over union value\n",
    "    return iou\n",
    "\n",
    "def get_center_of_box(box):\n",
    "    \"\"\"\n",
    "    Helper function to get the center of the box\n",
    "    :params: box - the coordinates of the box\n",
    "    :return: center - (x,y) coordinates of the center\n",
    "    \"\"\"\n",
    "    x_min, y_min, x_max, y_max = box\n",
    "    return int(x_min + (x_max-x_min)/2), int(y_min + (y_max-y_min)/2)\n",
    "\n",
    "def update(particles, frame, hist_roi_norm, prev_box, boxes, confidences, class_ids, w, h, stone_class, task_no=3):\n",
    "    \"\"\"\n",
    "    Update the weight of each particle based on how similar is to the target window \n",
    "    use a simple color histogram model essential step: how to update the weights.\n",
    "    :params: particles - the particles of the particle filter\n",
    "    :params: frame - the image frame\n",
    "    :params: hist_roi_norm - the normalized color histogram of the initial roi\n",
    "    :params: boxes - the boxes determined by the YOLO net\n",
    "    :params: confidences - the confidences determined by the YOLO net\n",
    "    :params: class_ids - the class ids determined by the YOLO net\n",
    "    :params: w - the width of the tracking box\n",
    "    :params: h - the width of the tracking box\n",
    "    :params: stone_class - the class of the initial stone\n",
    "    :params: task_no - the task no \n",
    "    \"\"\"\n",
    "    particles = np.int32(particles)   \n",
    "    weights = np.zeros((particles.shape[0]))\n",
    "\n",
    "    for i in range(particles.shape[0]):\n",
    "        particle_box = [particles[i, 0], particles[i, 1], particles[i, 0] + w - 1, particles[i, 1] + h - 1]\n",
    "\n",
    "        if task_no == 3:\n",
    "            # if no boxes were detected by the DNN then compare the color histograms\n",
    "            if len(boxes) == 0:\n",
    "                \n",
    "                img_particle = frame[particles[i, 1]: particles[i, 1] + h - 1, particles[i, 0]:particles[i, 0] + w - 1].copy()\n",
    "                img_particle = cv.cvtColor(img_particle, cv.COLOR_BGR2HSV)\n",
    "\n",
    "                particle_hist = cv.calcHist([img_particle], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])  \n",
    "\n",
    "                particle_hist_norm = particle_hist / particle_hist.sum()     \n",
    "\n",
    "                weights[i] = cv.compareHist(hist_roi_norm, particle_hist_norm, cv.HISTCMP_CHISQR_ALT)\n",
    "\n",
    "                weights[i] = np.exp(-2 * (weights[i] ** 2))  \n",
    "            else:\n",
    "                \n",
    "                particle_box = [particles[i, 0], particles[i, 1], particles[i, 0] + w - 1, particles[i, 1] + h - 1]\n",
    "\n",
    "                detection_overlap = False\n",
    "                \n",
    "                # see if there is an overlap between the detected boxes and the tracking box\n",
    "                for box, class_id in zip(boxes, class_ids):\n",
    "                    if class_id == stone_class:\n",
    "                        # if IOU between one detected box and the tracking box > 0.4 then there exists overlap\n",
    "                        if bb_intersection_over_union(box, prev_box) > 0.4:\n",
    "                            detection_overlap = True\n",
    "\n",
    "                # if we have overlap, update the weights of the particles according to the IOUs between the\n",
    "                # detected box-tracking box + particle box-detected box\n",
    "                if detection_overlap == True:\n",
    "                    # this variable will store the biggest overlap\n",
    "                    max_particle_importance = 0\n",
    "                    for box, confidence, class_id in zip(boxes, confidences, class_ids):\n",
    "                        if class_id == stone_class:\n",
    "                            particle_importance = bb_intersection_over_union(box, prev_box) + 3*bb_intersection_over_union(particle_box, box)\n",
    "                            if particle_importance > max_particle_importance:\n",
    "                                max_particle_importance = particle_importance\n",
    "                        \n",
    "                    weights[i] = max_particle_importance\n",
    "                    weights[i] = np.exp(2 * (weights[i] ** 2))  \n",
    "                else:\n",
    "                    # if no overlap then use the color histogram method\n",
    "                    img_particle = frame[particles[i, 1]: particles[i, 1] + h - 1, particles[i, 0]:particles[i, 0] + w - 1].copy()\n",
    "                    img_particle = cv.cvtColor(img_particle, cv.COLOR_BGR2HSV)\n",
    "\n",
    "                    particle_hist = cv.calcHist([img_particle], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])  \n",
    "\n",
    "                    particle_hist_norm = particle_hist / particle_hist.sum()     \n",
    "\n",
    "                    weights[i] = cv.compareHist(hist_roi_norm, particle_hist_norm, cv.HISTCMP_CHISQR_ALT)\n",
    "\n",
    "                    weights[i] = np.exp(-2 * (weights[i] ** 2))  \n",
    "\n",
    "        if task_no == 4:    \n",
    "            \n",
    "            max_particle_importance = 0\n",
    "            for box, confidence, class_id in zip(boxes, confidences, class_ids):\n",
    "                \n",
    "                if class_id == stone_class:\n",
    "                    particle_importance = bb_intersection_over_union(box, prev_box) + 10000*bb_intersection_over_union(particle_box, box)\n",
    "                    if particle_importance > max_particle_importance:\n",
    "                        max_particle_importance = particle_importance\n",
    "\n",
    "            weights[i] = max_particle_importance\n",
    "            weights[i] = np.exp(2 * (weights[i] ** 2))  \n",
    "\n",
    "            # img_particle = frame[particles[i, 1]: particles[i, 1] + h - 1, particles[i, 0]:particles[i, 0] + w - 1].copy()\n",
    "            # img_particle = cv.cvtColor(img_particle, cv.COLOR_BGR2HSV)\n",
    "\n",
    "            # particle_hist = cv.calcHist([img_particle], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])  \n",
    "\n",
    "            # particle_hist_norm = particle_hist / particle_hist.sum()     \n",
    "\n",
    "            # weights[i] = cv.compareHist(hist_roi_norm, particle_hist_norm, cv.HISTCMP_CHISQR_ALT)\n",
    "\n",
    "            # weights[i] = np.exp(-2 * (weights[i] ** 2))  \n",
    "                \n",
    "    weights += 1.e-10 # avoid round-off to zero\n",
    "    # normalize the wights such that we have a probability distribution\n",
    "    weights /= sum(weights) \n",
    "    return weights\n",
    "\n",
    "def write_video(frames, filename):\n",
    "    \"\"\"\n",
    "    Helper function to write a set of frames to an mp4 video file\n",
    "    :params: frames - the list of frames to be written\n",
    "    :params: filename - the name of the video file\n",
    "    \"\"\"\n",
    "    # here we have the extensions and the fourcc for each of it\n",
    "    video_extension_and_fourcc_dict = {'avi': cv.VideoWriter_fourcc('M', 'J', 'P', 'G'),\n",
    "                                       'mp4': 0x7634706d}   \n",
    "\n",
    "    # We need to create a VideoWriter object. \n",
    "    # First, we should specify the output file name with its format (eg: 1_fps_1.mp4). \n",
    "    # We should specify the FourCC code and the number of frames per second (FPS). \n",
    "    # Lastly, the frame size should be passed (width, height).\n",
    "\n",
    "    video_output_name = filename\n",
    "    # write at 20 fps\n",
    "    output_video = cv.VideoWriter(video_output_name, video_extension_and_fourcc_dict[\"mp4\"], 20.0,\n",
    "                                  (frames[0].shape[1], frames[0].shape[0]))\n",
    "\n",
    "    num_frames = len(frames)\n",
    "    # We know that the first video has 30 fps.\n",
    "    for i in range(0, num_frames):\n",
    "        output_video.write(frames[i]) # writing the frame\n",
    "\n",
    "    # don't forget to release the video writer\n",
    "    output_video.release()\n",
    "\n",
    "def evaluate_task3(train_or_test='Train'):\n",
    "    \"\"\"\n",
    "    Evaluate task 3 on the 'Task3' input set\n",
    "    :param train_or_test. The source of the files. It can be either 'train' or 'test'.\n",
    "            To find the input images, the root folder where the notebook is located is taken\n",
    "            into consideration.\n",
    "    :output. The files with the resulting output will be saved at:\n",
    "            <current_directory>/evaluation/submission_files/Task3/\"\n",
    "    \"\"\"\n",
    "    print(\"Evaluate task 3\")\n",
    "    # get the path to the images and define all the other necessary paths\n",
    "    imgs_path = list_of_files(dirname + \"\\\\\"  + train_or_test + \"\\\\Task3\\\\\", \"mp4\")\n",
    "    bbox_path = list_of_files(dirname + \"\\\\\"  + train_or_test + \"\\\\Task3\\\\\", \"txt\")\n",
    "    predictions_path_root = \"\\\\evaluation\\\\submission_files\\\\\"\n",
    "    predictions_path = dirname + predictions_path_root + \"Task3\\\\\"\n",
    "    \n",
    "    # 100 particles\n",
    "    num_particles=100\n",
    "    \n",
    "    # get the static files for the YOLO net\n",
    "    net = cv.dnn.readNet('yolov3_training_last.weights', 'yolov3_testing.cfg')\n",
    "    \n",
    "    for i in range(len(imgs_path)): \n",
    "        \n",
    "        print(\"img\", imgs_path[i].split(\"\\\\\")[-1].split(\".\")[0])\n",
    "        print(\"bbox\", bbox_path[i].split(\"\\\\\")[-1].split(\".\")[0])\n",
    "        \n",
    "        # split the first two lines of the .txt file\n",
    "        with open(bbox_path[i]) as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            no_of_frames = int(lines[0].split(\" \")[0])\n",
    "            bbox = lines[1].split(\" \")[1:]\n",
    "            bbox=[int(i) for i in bbox]\n",
    "\n",
    "        cap = cv.VideoCapture(imgs_path[i])\n",
    "        \n",
    "        current_frame = 0\n",
    "\n",
    "        ret, first_frame = cap.read() # Read the first frame      \n",
    "\n",
    "        # extract the roi of the first bounding box\n",
    "        img_roi, x, y, w, h = select_roi(first_frame,bbox) \n",
    "        \n",
    "        # take the information that is situated on the center of the roi image (there is more info about the color)\n",
    "        plt.imshow(cv.cvtColor(img_roi[int(h/8):int(5*h/8),int(2*w/8):int(6*w/8)], cv.COLOR_BGR2RGB))\n",
    "        \n",
    "        # classify the color of the roi\n",
    "        stone_class = color_classificator(cv.cvtColor(img_roi[int(h/8):int(5*h/8),int(2*w/8):int(6*w/8)], cv.COLOR_BGR2RGB))\n",
    "\n",
    "        print(\"Stone class\", stone_class)\n",
    "        \n",
    "        # convert the color to HSV and compute the normalized color histogram\n",
    "        img_roi = cv.cvtColor(img_roi[int(h/8):int(5*h/8),int(2*w/8):int(6*w/8)], cv.COLOR_BGR2HSV)\n",
    "        hist_roi = cv.calcHist([img_roi], [0 ,1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])  \n",
    "        hist_roi_norm = hist_roi / hist_roi.sum() \n",
    "\n",
    "        # initialize the particles using an uniform distribution\n",
    "        particles = create_uniform_particles([bbox[0], bbox[0]], [bbox[1], bbox[1]], num_particles)\n",
    "        velocity = [0, 0]\n",
    "        std = [25, 25] \n",
    "        \n",
    "        # append the first two lines in the bboxes array that will be written to *_predicted.txt file\n",
    "        bboxes = [[no_of_frames,-1,-1,-1,-1],[0,bbox[0],bbox[1],bbox[2],bbox[3]]]\n",
    "        \n",
    "        # use a mean of the box dimensions to have a dinamic changable dimension\n",
    "        mean_w = w\n",
    "        mean_h = h\n",
    "        \n",
    "        # create a queue with the last 10 dimensions of the image to smoothen the dimensions of new ones\n",
    "        previous_mean_w = deque(10*[w], 10)\n",
    "        previous_mean_h = deque(10*[h], 10)\n",
    "        \n",
    "        frames = []\n",
    "\n",
    "        # create a queue with the last 10 bounding boxes to remove the chance of a big drift\n",
    "        prev_boxes = deque(10*[[bbox[0],bbox[1],bbox[2],bbox[3]]], 10)\n",
    "\n",
    "        # calculate the mean box using the queue\n",
    "        prev_box = np.mean(np.array(prev_boxes), axis=0)\n",
    "\n",
    "        print(prev_box)\n",
    "        \n",
    "        j = 0\n",
    "        while(cap.isOpened()): \n",
    "            ret, frame = cap.read()\n",
    "            if ret: \n",
    "                j+=1\n",
    "                current_frame = current_frame + 1  \n",
    "\n",
    "                # get the detected boxes\n",
    "                boxes, confidences, class_ids = detect_frame(net, frame, show_detection=False)\n",
    "                \n",
    "                particles = predict(particles, velocity, std, frame, mean_w, mean_h)\n",
    "                \n",
    "                weights = update(particles, frame, hist_roi_norm, prev_box, boxes, confidences, class_ids, mean_w, mean_h, stone_class) \n",
    "                \n",
    "                obj = np.int32(estimate(particles, weights))       \n",
    "                \n",
    "                bboxes.append([current_frame, obj[0], obj[1], obj[0] + mean_w, obj[1] + mean_h])   \n",
    "                \n",
    "                annotated_image = frame.copy()\n",
    "                \n",
    "                for i in range(len(boxes)):\n",
    "                    x1, y1, x2, y2 = boxes[i]\n",
    "                    label = str(class_ids[i])\n",
    "                    confidence = str(round(confidences[i],2))\n",
    "                    color = (255,255,0)\n",
    "                    annotated_image = cv.rectangle(annotated_image, (x1,y1), (x2, y2), color, 2)\n",
    "                    annotated_image = cv.putText(annotated_image, label + \" \" + confidence, (x1, y1+20), cv.FONT_HERSHEY_PLAIN, 1, (255,255,255), 3)\n",
    "\n",
    "                velocity[0] = obj[0] - bbox[0]\n",
    "                velocity[1] = obj[1] - bbox[1]   \n",
    "                \n",
    "                bbox = obj.copy()\n",
    "\n",
    "                indexes = resample(weights) \n",
    "                particles, weights = resample_from_index(particles, weights, indexes)     \n",
    "                \n",
    "                annotated_image = cv.rectangle(annotated_image, (obj[0], obj[1]), (obj[0] + mean_w, obj[1] + mean_h), (0, 255, 255), 4)\n",
    "                annotated_image = cv.putText(annotated_image, str(j), (55,55), cv.FONT_HERSHEY_PLAIN, 3, (255,0,0), 3)\n",
    "\n",
    "                # update the boxes queue\n",
    "                prev_boxes.appendleft([obj[0], obj[1], obj[0] + mean_w, obj[1] + mean_h])\n",
    "                prev_box = np.int32(np.mean(np.array(prev_boxes), axis=0))\n",
    "\n",
    "                # print(prev_box)\n",
    "\n",
    "                frames.append(annotated_image)\n",
    "\n",
    "                # update the boxes dimensions queue\n",
    "                if len(boxes):\n",
    "                \n",
    "                    mean_w = 0\n",
    "                    mean_h = 0\n",
    "\n",
    "                    for box in boxes:\n",
    "                        mean_w += box[2]-box[0]\n",
    "                        mean_h += box[3]-box[1]\n",
    "\n",
    "                    mean_w = int(mean_w/len(boxes))\n",
    "                    mean_h = int(mean_h/len(boxes))\n",
    "\n",
    "                    previous_mean_w.appendleft(mean_w)\n",
    "                    previous_mean_h.appendleft(mean_h)\n",
    "\n",
    "                    mean_w = int(np.mean(list(previous_mean_w)))\n",
    "                    mean_h = int(np.mean(list(previous_mean_h)))\n",
    "                \n",
    "                print(j)\n",
    "\n",
    "                if no_of_frames is not None and current_frame > no_of_frames:\n",
    "                    break\n",
    "\n",
    "                \n",
    "            else:\n",
    "                break\n",
    "\n",
    "        img_no = imgs_path[i].split(\"\\\\\")[-1].split(\".\")[0]\n",
    "        print(bboxes)\n",
    "        # save the results, line by line, to *_predicted files\n",
    "        write_video(frames, predictions_path + str(img_no) + '_annotated.mp4')\n",
    "        with open(predictions_path + str(img_no) + '_predicted.txt','w') as f:\n",
    "            for j, line in enumerate(bboxes):\n",
    "                line_str = ' '.join(str(e) for e in line)\n",
    "                if j < len(bboxes):\n",
    "                    print(line_str)\n",
    "                    f.write(line_str + \"\\n\")\n",
    "                else:\n",
    "                    f.write(line_str)\n",
    "        \n",
    "        print(bboxes)\n",
    "                \n",
    "        # after playing the video, release the video capture    \n",
    "        cap.release()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     112
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluate_task4(train_or_test='Train'):\n",
    "    \"\"\"\n",
    "    Evaluate task 4 on the 'Task3' input set\n",
    "    :param train_or_test. The source of the files. It can be either 'train' or 'test'.\n",
    "            To find the input images, the root folder where the notebook is located is taken\n",
    "            into consideration.\n",
    "    :output. The files with the resulting output will be saved at:\n",
    "            <current_directory>/evaluation/submission_files/Task4/\"\n",
    "    \"\"\"\n",
    "    print(\"Evaluate task 4\")\n",
    "    \n",
    "    num_particles=100\n",
    "    \n",
    "    net = cv.dnn.readNet('yolov3_training_last.weights', 'yolov3_testing.cfg')\n",
    "    \n",
    "    if cuda.is_available():\n",
    "        net.setPreferableBackend(cv.dnn.DNN_BACKEND_CUDA)\n",
    "        net.setPreferableTarget(cv.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "    for k in range(1,11):\n",
    "        \n",
    "        cap = cv.VideoCapture(\"/videos/Task4/\"+str(k)+\".mp4\")\n",
    "\n",
    "        print(\"This is the \" + str(k) + \"-th video\")\n",
    "\n",
    "        no_of_frames = cap.get(cv.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "        current_frame = 0\n",
    "\n",
    "        particles = 0\n",
    "        velocity = [0, 0]\n",
    "        std = [25, 25] \n",
    "        bboxes = [[no_of_frames,-1,-1,-1,-1]]\n",
    "        \n",
    "        w = 0\n",
    "        h = 0\n",
    "\n",
    "        mean_w = w\n",
    "        mean_h = h\n",
    "        \n",
    "        previous_mean_w = []\n",
    "        previous_mean_h = []\n",
    "\n",
    "        prev_boxes = []\n",
    "\n",
    "        prev_box = 0\n",
    "\n",
    "        frames=[]\n",
    "\n",
    "        first_frame = True\n",
    "        confidenct_frame = False\n",
    "        stone_class = -1\n",
    "\n",
    "        hist_roi_norm = []\n",
    "\n",
    "        j = 0\n",
    "\n",
    "        was_perspective_changed = False\n",
    "\n",
    "        last_frame_hist = []\n",
    "        bbox = []\n",
    "\n",
    "        on_boundary_count = 0\n",
    "\n",
    "        while cap.isOpened(): \n",
    "            ret, frame = cap.read()\n",
    "            if ret: \n",
    "                j+=1\n",
    "                current_frame = current_frame + 1  \n",
    "\n",
    "                # detect boxes\n",
    "                boxes, confidences, class_ids = detect_frame(net, frame, show_detection=False)\n",
    "\n",
    "                annotated_image = frame.copy()\n",
    "\n",
    "                # changing in perspective\n",
    "                if last_frame_hist != [] and was_perspective_changed == False:\n",
    "                    current_frame_hist = cv.calcHist([frame], [0 ,1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])  \n",
    "                    current_frame_hist = current_frame_hist / current_frame_hist.sum() \n",
    "                    difference = cv.compareHist(last_frame_hist, current_frame_hist, cv.HISTCMP_CHISQR_ALT)\n",
    "                    # check if the Chi Squared difference between two consecutive histograms is bigger than 1.0\n",
    "                    if difference > 1.0:\n",
    "                        # show the before perspective changing image\n",
    "                        plt.figure()\n",
    "                        plt.imshow(frames[j-2])\n",
    "                        # show the after perspective changing image\n",
    "                        plt.figure()\n",
    "                        plt.imshow(frame)\n",
    "                        plt.show()\n",
    "                        was_perspective_changed = True\n",
    "                        print(difference)\n",
    "                        annotated_image = cv.putText(annotated_image, \"Perspective Changed\", (100, 100), cv.FONT_HERSHEY_PLAIN, 3, (255,255,0), 3)\n",
    "\n",
    "                        for a in range(30):\n",
    "                            frames.append(annotated_image)\n",
    "\n",
    "                        # find the box with the best confidence\n",
    "                        best_confidence = 0\n",
    "                        best_box = []\n",
    "                        if len(boxes) > 0:\n",
    "                            for box, confidence, class_id in zip (boxes, confidences, class_ids):\n",
    "                                if confidence > best_confidence and class_id == stone_class:\n",
    "                                    best_confidence = confidence\n",
    "                                    best_box = box\n",
    "                    \n",
    "                        # the box that has the best confidence will be taken into consideration as the start point for \n",
    "                        # a new particle filter\n",
    "                        if best_confidence > 0.5:\n",
    "                            bbox = best_box\n",
    "\n",
    "                            bboxes.append([0,bbox[0],bbox[1],bbox[2],bbox[3]])\n",
    "\n",
    "                            particles = create_uniform_particles([bbox[0], bbox[0]], [bbox[1], bbox[1]], num_particles)\n",
    "\n",
    "                            img_roi, _, _, w, h = select_roi(frame,bbox) \n",
    "\n",
    "                            img_roi = cv.cvtColor(img_roi, cv.COLOR_BGR2HSV)\n",
    "\n",
    "                            hist_roi = cv.calcHist([img_roi], [0 ,1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])  \n",
    "                            hist_roi_norm = hist_roi / hist_roi.sum() \n",
    "\n",
    "                            previous_mean_w = deque(10*[w], 10)\n",
    "                            previous_mean_h = deque(10*[h], 10)\n",
    "\n",
    "                            prev_boxes = deque(10*[[bbox[0],bbox[1],bbox[2],bbox[3]]], 10)\n",
    "\n",
    "                            prev_box = np.mean(np.array(prev_boxes), axis=0)\n",
    "\n",
    "                            mean_w = int(np.mean(list(previous_mean_w)))\n",
    "                            mean_h = int(np.mean(list(previous_mean_h)))\n",
    "\n",
    "                            annotated_image = cv.rectangle(annotated_image, [best_box[0], best_box[1]], [best_box[0] + w, best_box[1]+h], (255,0,0), 10)\n",
    "\n",
    "                            on_boundary_count = 0\n",
    "                    \n",
    "                    last_frame_hist = current_frame_hist\n",
    "\n",
    "                # all the predictions that are not the initial one and the perspective changing one\n",
    "                if first_frame == False:\n",
    "                \n",
    "                    particles = predict(particles, velocity, std, frame, mean_w, mean_h)\n",
    "                    \n",
    "                    weights = update(particles, frame, hist_roi_norm, prev_box, boxes, confidences, class_ids, mean_w, mean_h, stone_class, task_no=4) \n",
    "                    \n",
    "                    obj = np.int32(estimate(particles, weights))       \n",
    "                    \n",
    "                    # check if the stone went out of image\n",
    "                    if obj[1] + mean_h > frame.shape[0] - 10:\n",
    "                        # annotated_image = cv.putText(annotated_image, \"ON BOUNDARY\", (200, 200), cv.FONT_HERSHEY_PLAIN, 1, (255,255,255), 3)\n",
    "                        on_boundary_count += 1\n",
    "\n",
    "                    if on_boundary_count < 10:\n",
    "\n",
    "                        bboxes.append([current_frame, obj[0], obj[1], obj[0] + mean_w, obj[1] + mean_h])   \n",
    "                        print([obj[0], obj[1], obj[0] + mean_w, obj[1] + mean_h])\n",
    "\n",
    "                        velocity[0] = obj[0] - bbox[0]\n",
    "                        velocity[1] = obj[1] - bbox[1]   \n",
    "                        \n",
    "                        bbox = obj.copy()\n",
    "\n",
    "                        indexes = resample(weights) \n",
    "                        particles, weights = resample_from_index(particles, weights, indexes)     \n",
    "\n",
    "                        annotated_image = cv.rectangle(annotated_image, (obj[0], obj[1]), (obj[0] + mean_w, obj[1] + mean_h), (0, 255, 255), 4)\n",
    "                        annotated_image = cv.putText(annotated_image, str(j), (55,55), cv.FONT_HERSHEY_PLAIN, 3, (255,0,0), 3)\n",
    "\n",
    "                        prev_boxes.appendleft([obj[0], obj[1], obj[0] + mean_w, obj[1] + mean_h])\n",
    "                        prev_box = np.int32(np.mean(np.array(prev_boxes), axis=0))\n",
    "\n",
    "                        if len(boxes):\n",
    "                        \n",
    "                            mean_w = 0\n",
    "                            mean_h = 0\n",
    "\n",
    "                            for box in boxes:\n",
    "                                mean_w += box[2]-box[0]\n",
    "                                mean_h += box[3]-box[1]\n",
    "\n",
    "                            mean_w = int(mean_w/len(boxes))\n",
    "                            mean_h = int(mean_h/len(boxes))\n",
    "\n",
    "                            previous_mean_w.appendleft(mean_w)\n",
    "                            previous_mean_h.appendleft(mean_h)\n",
    "\n",
    "                            mean_w = int(np.mean(list(previous_mean_w)))\n",
    "                            mean_h = int(np.mean(list(previous_mean_h)))\n",
    "                    \n",
    "                # intialization phase\n",
    "                if first_frame == True:\n",
    "\n",
    "                    # print(boxes)\n",
    "                    best_confidence = 0\n",
    "                    best_box = []\n",
    "                    if len(boxes) > 0:\n",
    "                        for box, confidence, class_id in zip (boxes, confidences, class_ids):\n",
    "                            if confidence > best_confidence:\n",
    "                                best_confidence = confidence\n",
    "                                best_box = box\n",
    "                                stone_class = class_id\n",
    "                \n",
    "                    # a good match found\n",
    "                    if best_confidence > 0.95:\n",
    "                        bbox = best_box\n",
    "\n",
    "                        bboxes.append([0,bbox[0],bbox[1],bbox[2],bbox[3]])\n",
    "\n",
    "                        particles = create_uniform_particles([bbox[0], bbox[0]], [bbox[1], bbox[1]], num_particles)\n",
    "\n",
    "                        img_roi, _, _, w, h = select_roi(frame,bbox) \n",
    "\n",
    "                        # plt.figure()\n",
    "                        # plt.imshow(cv.cvtColor(img_roi, cv.COLOR_BGR2RGB))\n",
    "\n",
    "                        img_roi = cv.cvtColor(img_roi, cv.COLOR_BGR2HSV)\n",
    "\n",
    "                        hist_roi = cv.calcHist([img_roi], [0 ,1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])  \n",
    "                        hist_roi_norm = hist_roi / hist_roi.sum() \n",
    "\n",
    "                        previous_mean_w = deque(10*[w], 10)\n",
    "                        previous_mean_h = deque(10*[h], 10)\n",
    "\n",
    "                        prev_boxes = deque(10*[[bbox[0],bbox[1],bbox[2],bbox[3]]], 10)\n",
    "\n",
    "                        prev_box = np.mean(np.array(prev_boxes), axis=0)\n",
    "\n",
    "                        # print(previous_mean_w, previous_mean_h, prev_boxes, prev_box)\n",
    "\n",
    "                        \n",
    "                        last_frame_hist = cv.calcHist([frame], [0 ,1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])  \n",
    "                        last_frame_hist = last_frame_hist / last_frame_hist.sum() \n",
    "\n",
    "                        annotated_image = cv.rectangle(annotated_image, [best_box[0], best_box[1]], [best_box[0] + w, best_box[1]+h], (255,0,0), 10)\n",
    "\n",
    "                        first_frame = False\n",
    "\n",
    "\n",
    "                frames.append(annotated_image)\n",
    "\n",
    "                print(\"frame\", str(j))\n",
    "                if no_of_frames is not None and current_frame > no_of_frames:\n",
    "                    break\n",
    "\n",
    "                \n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        # after playing the video, release the video capture    \n",
    "        cap.release()       \n",
    "            \n",
    "evaluate_task4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
